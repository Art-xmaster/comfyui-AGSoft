"""
# AGSoft VideoFrameExtractor
# –ê–≤—Ç–æ—Ä: AGSoft
# –î–∞—Ç–∞: 06.12.2025 –≥.
–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–¥—Ä—ã –∏–∑ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ —Å –≥–∏–±–∫–∏–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –≤—ã–±–æ—Ä–∞.
–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã –≤—ã–±–æ—Ä–∫–∏ –∫–∞–¥—Ä–æ–≤ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –≤–∏–¥–µ–æ.
"""

# –ò–º–ø–æ—Ä—Ç—ã —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫ Python
import os
import json
import logging
from typing import Tuple, List, Dict, Any, Optional

# –ò–º–ø–æ—Ä—Ç—ã –∏–∑ ComfyUI
import folder_paths
import torch
import numpy as np

# –ò–º–ø–æ—Ä—Ç OpenCV –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–∏–¥–µ–æ
try:
    import cv2
except ImportError:
    raise ImportError("OpenCV (cv2) is required for this node. Please install it with 'pip install opencv-python'.")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞
logger = logging.getLogger(__name__)


class AGSoftVideoFrameExtractor:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –Ω–æ–¥—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤ –∏–∑ –≤–∏–¥–µ–æ.
    """

    @classmethod
    def INPUT_TYPES(cls) -> Dict[str, Any]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–æ–¥—ã.
        """
        return {
            "required": {
                "custom_path": (
                    "STRING",
                    {
                        "default": "",
                        "multiline": False,
                        "tooltip": (
                            "Absolute or relative path to the video file. "
                            "This has the highest priority.\n"
                            "–ê–±—Å–æ–ª—é—Ç–Ω—ã–π –∏–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å –∫ –≤–∏–¥–µ–æ—Ñ–∞–π–ª—É. "
                            "–ò–º–µ–µ—Ç –Ω–∞–∏–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç."
                        )
                    },
                ),
                "frame_selection_mode": (
                    ["first", "last", "exact_frame", "range", "sample", "all"],
                    {
                        "default": "first",
                        "tooltip": """
first: Extracts the very first frame.
last: Extracts the very last frame (robust method).
exact_frame: Extracts a single frame by its number.
range: Extracts frames from 'start_frame' to 'end_frame' with 'step'.
sample: Extracts 'num_frames' evenly spaced frames.
all: Extracts all frames with the given 'step'.

first: –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∞–º—ã–π –ø–µ—Ä–≤—ã–π –∫–∞–¥—Ä.
last: –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–∞–º—ã–π –ø–æ—Å–ª–µ–¥–Ω–∏–π –∫–∞–¥—Ä (–Ω–∞–¥–µ–∂–Ω—ã–º –º–µ—Ç–æ–¥–æ–º).
exact_frame: –ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–¥–∏–Ω –∫–∞–¥—Ä –ø–æ –µ–≥–æ –Ω–æ–º–µ—Ä—É.
range: –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–¥—Ä—ã –æ—Ç 'start_frame' –¥–æ 'end_frame' —Å —à–∞–≥–æ–º 'step'.
sample: –ò–∑–≤–ª–µ–∫–∞–µ—Ç 'num_frames' —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤.
all: –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –∫–∞–¥—Ä—ã —Å –∑–∞–¥–∞–Ω–Ω—ã–º —à–∞–≥–æ–º 'step'.
"""
                    },
                ),
            },
            "optional": {
                "exact_frame": (
                    "INT",
                    {
                        "default": 1, "min": 1, "max": 10000000,
                        "tooltip": """
Frame number to extract (1-based index). Used only in 'exact_frame' mode.
–ù–æ–º–µ—Ä –∫–∞–¥—Ä–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è (–Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 1). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ 'exact_frame'.
"""
                    },
                ),
                "start_frame": (
                    "INT",
                    {
                        "default": 1, "min": 1, "max": 10000000,
                        "tooltip": """
Starting frame number for 'range' mode (1-based index). Used only in 'range' mode.
–ù–∞—á–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –∫–∞–¥—Ä–∞ –¥–ª—è —Ä–µ–∂–∏–º–∞ 'range' (–Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 1). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ 'range'.
"""
                    },
                ),
                "end_frame": (
                    "INT",
                    {
                        "default": 100, "min": 1, "max": 10000000,
                        "tooltip": """
Ending frame number for 'range' mode (1-based index). Used only in 'range' mode.
–ö–æ–Ω–µ—á–Ω—ã–π –Ω–æ–º–µ—Ä –∫–∞–¥—Ä–∞ –¥–ª—è —Ä–µ–∂–∏–º–∞ 'range' (–Ω—É–º–µ—Ä–∞—Ü–∏—è —Å 1). –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ 'range'.
"""
                    },
                ),
                "num_frames": (
                    "INT",
                    {
                        "default": 10, "min": 1, "max": 10000000,
                        "tooltip": """
Number of frames to extract in 'sample' mode. Used only in 'sample' mode to determine how many frames to evenly distribute across the video.
–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –≤ —Ä–µ–∂–∏–º–µ 'sample'. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ 'sample' –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–∞–¥—Ä–æ–≤, —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –ø–æ –≤–∏–¥–µ–æ.
"""
                    },
                ),
                "step": (
                    "INT",
                    {
                        "default": 10, "min": 1, "max": 1000000,
                        "tooltip": """
Extract every Nth frame. For example, step=2 will extract every second frame, reducing the total number of frames by half. 
Used only in 'range' and 'all' modes.
–ò–∑–≤–ª–µ–∫–∞—Ç—å –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä. –ù–∞–ø—Ä–∏–º–µ—Ä, step=2 –±—É–¥–µ—Ç –∏–∑–≤–ª–µ–∫–∞—Ç—å –∫–∞–∂–¥—ã–π –≤—Ç–æ—Ä–æ–π –∫–∞–¥—Ä, —É–º–µ–Ω—å—à–∞—è –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –≤–¥–≤–æ–µ. 
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–∞—Ö 'range' –∏ 'all'.
"""
                    },
                ),
            },
        }

    RETURN_TYPES = ("IMAGE", "INT", "INT", "INT", "STRING")
    RETURN_NAMES = ("frame", "width", "height", "total_frames", "video_metadata_json")
    FUNCTION = "extract_frames"
    CATEGORY = "AGSoft/Video"
    DESCRIPTION = """
Extracts frames from a video file with flexible selection options. Supports various modes including extracting the first/last frame, specific frames, frame ranges, or all frames with customizable step and maximum frame limits. Returns the extracted frames as images along with video metadata.

–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–∞–¥—Ä—ã –∏–∑ –≤–∏–¥–µ–æ—Ñ–∞–π–ª–∞ —Å –≥–∏–±–∫–∏–º–∏ –æ–ø—Ü–∏—è–º–∏ –≤—ã–±–æ—Ä–∞. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ä–µ–∂–∏–º—ã, –≤–∫–ª—é—á–∞—è –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ/–ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤, –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤ –∫–∞–¥—Ä–æ–≤ –∏–ª–∏ –≤—Å–µ—Ö –∫–∞–¥—Ä–æ–≤ —Å –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–º —à–∞–≥–æ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–∞–¥—Ä–æ–≤. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã –∫–∞–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–º–µ—Å—Ç–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ –≤–∏–¥–µ–æ.
"""

    def extract_frames(
        self,
        custom_path: str,
        frame_selection_mode: str,
        exact_frame: Optional[int] = None,
        start_frame: Optional[int] = None,
        end_frame: Optional[int] = None,
        num_frames: Optional[int] = None,
        step: Optional[int] = None,
    ) -> Tuple[torch.Tensor, int, int, int, str]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–∞–¥—Ä–æ–≤.
        """
        # --- –®–∞–≥ 1: –ü—É—Ç—å –∫ –≤–∏–¥–µ–æ ---
        if not custom_path:
            raise ValueError("custom_path is required and cannot be empty.")
        video_path = os.path.abspath(custom_path)
        if not os.path.exists(video_path):
            raise FileNotFoundError(f"Video file not found at path: {video_path}")

        # --- –®–∞–≥ 2: –û—Ç–∫—Ä—ã—Ç–∏–µ –≤–∏–¥–µ–æ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö ---
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            raise ValueError(f"Could not open video file: {video_path}")

        fps = cap.get(cv2.CAP_PROP_FPS)
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # –£—Ç–æ—á–Ω–µ–Ω–∏–µ total_frames –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ —á—Ç–µ–Ω–∏—è –≤–∏–¥–µ–æ
        if total_frames > 0:
            cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)
            ret, _ = cap.read()
            if not ret:
                logger.warning("OpenCV CAP_PROP_FRAME_COUNT is inaccurate. Trying to find last valid frame...")
                found = False
                for i in range(1, 21):  # –º–∞–∫—Å–∏–º—É–º 20 –ø–æ–ø—ã—Ç–æ–∫
                    test_idx = max(0, total_frames - 1 - i)
                    cap.set(cv2.CAP_PROP_POS_FRAMES, test_idx)
                    ret, _ = cap.read()
                    if ret:
                        total_frames = test_idx + 1
                        found = True
                        break
                if not found:
                    logger.warning("Could not verify any frame near the end. Using CAP_PROP_FRAME_COUNT as-is.")
        else:
            total_frames = 0

        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)

        # --- –®–∞–≥ 3: –†–∞—Å—á—ë—Ç –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–∞–¥—Ä–æ–≤ ---
        frame_indices = self._calculate_frame_indices(
            frame_selection_mode,
            total_frames,
            exact_frame,
            start_frame,
            end_frame,
            num_frames,
            step
        )

        # --- –®–∞–≥ 4: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ ---
        frames = []
        for idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()
            if ret:
                frames.append(frame)
            else:
                logger.warning(f"Could not read frame at index {idx}. Skipping.")

        cap.release()

        if not frames:
            raise RuntimeError("No frames were successfully extracted.")

        # --- –®–∞–≥ 5: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Ç–µ–Ω–∑–æ—Ä ---
        frames_np = np.array(frames)  # Shape: (N, H, W, 3) in BGR
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ negative strides
        frames_rgb = np.ascontiguousarray(frames_np[..., ::-1])  # BGR ‚Üí RGB + contiguous
        frames_tensor = torch.from_numpy(frames_rgb).float() / 255.0

        # --- –®–∞–≥ 6: JSON —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏ ---
        metadata_json = self._create_metadata_json(
            video_path=video_path,
            width=width,
            height=height,
            total_frames=total_frames,
            fps=fps,
            frame_selection_mode=frame_selection_mode,
            frame_indices=frame_indices,
            node_params={
                "exact_frame": exact_frame,
                "start_frame": start_frame,
                "end_frame": end_frame,
                "num_frames": num_frames,
                "step": step,
            }
        )

        return (frames_tensor, width, height, total_frames, metadata_json)

    def _calculate_frame_indices(
        self,
        mode: str,
        total_frames: int,
        exact_frame: Optional[int],
        start_frame: Optional[int],
        end_frame: Optional[int],
        num_frames: Optional[int],
        step: Optional[int],
    ) -> List[int]:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Å–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤ –∫–∞–¥—Ä–æ–≤ (0-based)."""
        if total_frames == 0:
            return []

        if mode == "first":
            return [0]
        elif mode == "last":
            return [total_frames - 1]
        elif mode == "exact_frame":
            return [max(0, min(exact_frame - 1, total_frames - 1))]
        elif mode == "range":
            start_0b = max(0, start_frame - 1)
            end_0b = min(end_frame - 1, total_frames - 1)
            step_val = step if step is not None else 1
            return list(range(start_0b, end_0b + 1, step_val))
        elif mode == "sample":
            if num_frames is None or num_frames <= 0:
                num_frames = 10
            if num_frames >= total_frames:
                return list(range(total_frames))
            indices = np.round(np.linspace(0, total_frames - 1, num_frames)).astype(int)
            return indices.tolist()
        elif mode == "all":
            step_val = step if step is not None else 1
            return list(range(0, total_frames, step_val))
        else:
            raise ValueError(f"Unknown frame selection mode: {mode}")

    def _create_metadata_json(
        self,
        video_path: str,
        width: int,
        height: int,
        total_frames: int,
        fps: float,
        frame_selection_mode: str,
        frame_indices: List[int],
        node_params: Dict[str, Any],
    ) -> str:
        """–°–æ–∑–¥–∞—ë—Ç JSON-—Å—Ç—Ä–æ–∫—É —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏."""
        metadata = {
            "video_info": {
                "path": video_path,
                "width": width,
                "height": height,
                "total_frames": total_frames,
                "fps": round(fps, 2) if fps > 0 else 0,
                "duration_seconds": round(total_frames / fps, 2) if fps > 0 else 0,
                "orientation": "landscape" if width >= height else "portrait",
            },
            "node_execution_params": {
                "frame_selection_mode": frame_selection_mode,
                **{k: v for k, v in node_params.items() if v is not None},
            },
            "extracted_frame_indices_1_based": [idx + 1 for idx in frame_indices],
            "extracted_frame_count": len(frame_indices),
        }
        return json.dumps(metadata, indent=4, ensure_ascii=False)


# --- –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –Ω–æ–¥—ã ---
NODE_CLASS_MAPPINGS = {
    "AGSoftVideoFrameExtractor": AGSoftVideoFrameExtractor
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AGSoftVideoFrameExtractor": "üé¨AGSoft VideoFrameExtractor"
}